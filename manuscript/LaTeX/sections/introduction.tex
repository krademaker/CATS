\section{Introduction}
    Chromosomal instability is one of the hallmarks of cancer. Chromosomal aberrations affect transcriptional activity and thus greatly affect the diagnosis, progression, and prediction of response to treatment in different tumors (\citealp{Kloosterman2014}). Cancer is classified in molecular distinct subgroups that differ significantly in prognosis and patient survival rates (\citealp{VantVeer2002}) and evidence has been found that patterns of chromosomal copy number aberrations (CNAs) differ clearly between subgroups, for example, in colorectal cancer (\citealp{VanDenBroek2015}). These so-called \textit{molecular signatures} of chromosomal copy number aberrations could potentially be used to build classifiers to improve diagnosis and thus treatment of cancer patients.

    In the first instance, microarray gene expression profiles were used as a tool to identify subpopulations and to perform diagnostic and prognostic predictions in the field of cancer (\citealp{VantVeer2002}). However,  the introduction of array comparative genomic hybridization (aCGH) opened doors for the development of DNA-based diagnostic and prognostic predictors by investigating DNA copy number changes on a genome-wide scale (\citealp{Redon2009}). Methodologically, genomic experimental DNA and reference DNA are both hybridized on an array containing genomic sequences of the corresponding species. In the context of cancer, DNA copy number profiles are subjected to several pre-processing methods to improve further biological analysis regarding tumor progression, survival and treatment outcome. Pre-processing involves quality measures like median absolute deviation (MAD) for the exclusion of outliers; removal of artifacts caused by technical and biological parameters (e.g. density of G and C nucleotides, DNA quantity and quality); calling, which assigns discrete states ('loss'; $<$ 2 copies, 'gain'; 2 - 4 copies or amplification; $>$ 4 copies) to the regions; and segmentation, which clusters the chromosomal regions together, however assuming a homogeneous relationship (\citealp{VandeWiel2011}).

    From a machine learning point of view, these molecular signatures of cancer patients face the problem that there are many more features to discriminate between cancer patients than there are samples -  the so-called curse of dimensionality. For training purposes and to reduce the risk of overfitting, dimension-reduction is required in the form of \textit{feature selection}. Multiple methods exists to select important features: filter methods, which are univariate methods that rank features in terms of importance and are commonly statistical measures (e.g. Student's t-test, Chi-squared or Wilcoxon sum-rank test); wrapper methods, which iteratively remove (backward selection) or add (forward selection) features that contribute to the predictive power for the predictor; and embedded methods, which are learning algorithms which select features during training. Suprisingly, (\citealp{Haury2011}) found that filter methods that are more simple can outperform wrapper or embedded methods. However, Boruta, a wrapper method for feature selection, has proved to be a powerful approach to -omics data as shown in previous work (\citealp{degenhardt2019}) and is, therefore, justified for application to aCGH data. Additionally, 'simple' classification algorithms (e.g. nearest centroids or K-nearest neighbours) have been shown to perform above expectations in multiple gene expression datasets (\citealp{Haury2011,Wessels2005}). For this reason, the effect that different feature selection methods have on the overall performance of 'simple' classifiers has to be explored further. It remains relatively unclear which feature selection methods, forward or wrapper method, in combination with 'simple' classification algorithms based on chromosomal copy number aberrations give the highest performance for the prediction of cancer subgroups.

    In this paper, we aim to investigate 1) the use of CNA patterns for the classification of breast cancer subgroups and 2) the effect of a statistical filter method, Pearsonâ€™s chi-squared test, and a wrapper method, Boruta, on the performance of classification algorithms. We evaluated three distinct classification methods: Nearest Shrunken Centroid (NSC), K-Nearest Neighbour (KNN) and Neural Network. KNN is considered a 'simple' algorithm according to (\citealp{Haury2011}) and seems to outperform other more 'complex' algorithms. Additionally, NSC is a potentially useful algorithm in classifying subpopulations in high-dimensional datasets (\citealp{tibshirani2003}). Feed-forward neural networks with a single hidden (SLFN) layer have been found to perform significantly better in comparison to other popular and powerful classification methods (\citealp{huynh2007}). All of the above methods were trained on the data consisting of the chromosomal copy number aberrations of 100 breast cancer tumors divided into three subgroups based on pathological analysis. The performance of the feature selection method and classifier algorithm combination was evaluated using a nested 10-fold cross validation scheme, calculating accuracy for overall performance and the specificity \& sensitivity for class-specific performance. The ultimate goal of this study is to produce a classification model that predicts the subgroup of unclassified breast cancer samples with the highest possible accuracy.